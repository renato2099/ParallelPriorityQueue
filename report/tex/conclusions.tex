\section{Conclusions}
\label{sec:con}
%Here you need to summarize what you did and why this is important. {\em Do not take the abstract} and put it in the past tense. Remember, now the reader has (hopefully) read the paper, so it is a very different situation from the abstract. Try to highlight important results and say the things you really want to get across such as high-level statements (e.g., we believe that .... is the right approach to .... Even though we only considered the DFT, the .... technique should be applicable ....) You can also formulate next steps if you want. Be brief

%TODO review and add more things
Implementing a truly concurrent data structure is a challenging task because of many reasons. For instance, even though our implementation is lock-free, it may not be starvation-free. There could be a thread A that when going through the lowest level of the skip list searching for the next un-marked node (i.e. logically undeleted) gets always outrun by some other thread B. This means that thread A can fail repeatedly if the others threads always succeed. Moreover, thread contention may happen if many threads try to logically delete a node (i.e. mark a node). Only one thread will succeed and all the other unsuccessful ones will race to mark 
the next available node. 
%Another problem could arise when some node physically deletes a node that other threads are still using. This will lead into repeated \textit{compareAndSet} failures.

Doing experiments with different microarchitectures has lead us to deeper understanding of the tradeoffs in each of them. Utilizing the XeonPhi (MIC architecture) for our data structure means that every every time a thread updates a node, the operation will also be copied 
into the remote caches due to the tag-directory cache with explicit updates present on the Xeon Phi. Being able to update all CPUs at once does not show any performance gain because multiple writes cause more traffic and more invalidations which is a more expensive operation on the XeonPhi. On the other hand, our implementation gains performance in a microarchitecture with bigger caches size (e.g. Intel Haswell). This hardware enhancement helps us change the operational intensity of our data structure, making it compute bound and not memory bound any more. Thus, we can load more elements each time improving its spatial locality.