\section{Conclusions}
\label{sec:con}
%TODO review and add more things
Implementing a truly concurrent data structure is a challenging task for many reasons. For instance, even though our implementation is lock-free, it may not be starvation-free. There could be a thread A that when going through the lowest level of the skip list searching for the next un-marked node (i.e. logically undeleted) gets always outrun by some other thread B. This means that thread A can fail repeatedly if the others threads always succeed. Moreover, thread contention may happen if many threads try to logically delete a node (i.e. mark a node). Only one thread will succeed and all the other unsuccessful ones will race to mark 
the next available node. 
%Another problem could arise when some node physically deletes a node that other threads are still using. This will lead into repeated \textit{compareAndSet} failures.

Doing experiments with different microarchitectures has lead us to deeper understanding of the tradeoffs in each of them. For instance, utilizing the Xeon Phi for our data structure means that every every time a thread updates a node, the operation will also be copied into the remote caches due to the tag-directory cache with explicit updates present on the Xeon Phi. Being able to update all CPUs at once does not show any performance gain because multiple writes cause more traffic and more invalidations which is a more expensive operation on the Xeon Phi. On the other hand, our implementation gains performance in a microarchitecture with bigger caches size (e.g. Intel Haswell). This hardware enhancement helps us change the operational intensity of our data structure, making it compute bound and not memory bound any more. Thus, we can load more elements each time improving its spatial locality.