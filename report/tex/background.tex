\section{Background}
\label{sec:background}

When implementing a priority queue different underlying data structures can be used.
A common implementation a binary-heap which is based on an array. It requires $\mathcal{O}(\log{}n)$ time complexity for \textit{push} and \textit{pop} operations, and has a space complexity of $\mathcal{O}(n)$ .\\
Two baseline implementations are used to compare with our work. The \textit{priority\_queue} from the C++ standard library (STD)[REF] and the \textit{concurrent\_priotiy\_queue} implemented in the Intel TBB library[REF].
The TBB implementation is based on concurrent vectors while the STD implementation uses by default vectors as the underlying data structure. For our experimental evaluation the STD implementation was mad thread-safe by adding a single mutex wich serializes any access to the data structure.\\
Our lock-free implementation is based on a skip list \cite{Pugh:1990:SLP:78973.78977}. As shown in figure XYZ a skip list is a multi-level list where the bottom list is equal to single-linked list. The upper level lists have less elements, in other words are skipping some elements, thereby reducing the time to traverse them. Over how many levels a certain element spawns is determined upon insertion. Every element is inserted into the bottom level and reaches the next level with a probability of 0.5, this means it occurs in level 2 with probability 0.5 and in level 3 with probability 0.25 and so on. This leads to an index which asymptotically is equal to a binary tree, therefor any element on the bottom level can be accessed in $\mathcal{O}(\log{}n)$. Since the elment are sorted at the bottom level dequeuing the smallest element only takes $\mathcal{O}(1)$.\\
On average any node has two pointers to other nodes and thereby the same size as a node in a binary tree or heap. This means the memory consumption of a skip list is comparable.\\
A lockfree Skiplist is a good choice for a concurrent datastructure since the atomic operations are very local to 2-3 nodes and thereby the probabilty of conflicts between threads is minimized. Since our final goal was a port on to the Xeon Phi which comes with 60 cores this would be a good fit.\\
