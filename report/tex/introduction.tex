\section{Introduction}\label{sec:intro}

A priority queue is a data structure similar to a queue, where each element is associated with a priority key.
Thus, each element has a pair of value and key.
An element with high priority is served before an element with low priority.
The \textit{push} and \textit{pop} are the two basic operations.
A number of well known applications e.g. Dijkstra's algorithm, and Huffman coding are based on a priority queue.
In addition, a priority queue is also used in system level applications that are related to scheduling.
Hence, many different single-threaded implementations have been proposed.

The trend of processors technology has moved from single-core to multi-core.
Therefore, the research community has focused on parallelization of single-threaded applications and the implementation of efficient concurrent data structures.
Multiple threads may access the same priority queue at the same time in multithreading applications.
Consequently, the constistency of a priority queue has to be ensured explicitly.
Mutual exclusion, using locks, semaphores and etc., is a simple, but not an efficient solution to that problem, since it causes blocking, deadlocks, and limits scalability.
Atomic synchronization primitives that are available on every common CPU is an alternative way to implement an efficient concurrent priority queue.

In this paper, we present a lock-free concurrent priority queue, which supports fast \textit{pop} operation, by exploiting the underlying data structure.
It is based on a skip list \cite{Pugh:1990:SLP:78973.78977}, which provides probabilistic balancing using multiple levels, and maintains an ordered list of keys.

A concurrent priority queue which is based on a heap and is suitable for CUDA's data parallel SIMT architecture is presented in \cite{DBLP:conf/hipc/HeAP12}.
Wide heap nodes are used in order thousands of push and pop operations to be supported at the same time.
A lock-free concurrent priority queue which uses a skip list, as the underlying data structure, is presented in \cite{Sundell:2005:FLC:1073765.1073770}.
Our lock-free implementation is also based on a skip list, but the algorithm that is used is different, and the comparison is not limited to lock-based implementations. 

% TODO Xeon CPU or i7?
The rest of this, is organized as follows.
In the next section we give a brief, yet sufficient description of priority queues and skip lists. 
A detailed description of our implementation can be found in section \ref{sec:approach}.
Section \ref{sec:exp} presents experimental results collected from a Xeon CPU and Xeon Phi, by comparing the lock-free implementation with the Threading Building Blocks (TBB) concurrent priority queue, and two different implementations using mutual exclusion.
Finally, we draw some conlusions, summarizing this work.

%\mypar{Related work} Next, you have to give a brief overview of related work. For a paper like this, anywhere between 2 and 8 references. Briefly explain what they do. In the end contrast to what you do to make now precisely clear what your contribution is.
