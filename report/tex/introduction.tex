\section{Introduction}\label{sec:intro}

% Of course a priority queue is similar to a queue . . . they are both queues?
A priority queue is an abstract data structure in which all the elements in it are associated with a priority key.
Thus, each element in a priority queue consists of a key-value pair.
Priority queues have two basic operations: \textit{push} elements into it and \textit{pop} the element with the highest priority i.e. an element with higher priority is served before an element with a lower priority.

A number of well known applications (e.g. job scheduling, constraint systems, Dijkstra's algorithm, encoding algorithms) use on a priority queue.
%In addition, a priority queue is also used in system level applications that are related to scheduling.
Hence, many different single-threaded implementations have been proposed.
The trend of processors technology has moved from single-core to multi-core.
Therefore, the research community has focused on parallelization of single-threaded applications and the implementation of efficient concurrent data structures.
Multiple threads may access the same priority queue at the same time in multithreading applications.
Consequently, the consistency of a priority queue has to be ensured explicitly.
Mutual exclusion, i.e. using locks, semaphores or other primitives, might present a feasible solution, but not an optimal solution for our goal. This is because  it may cause blocking, deadlocks and a limited scalability.
Atomic synchronization primitives available on every common CPU are an alternative way to implement an efficient concurrent priority queue.

In this paper, we present a lock-free concurrent priority queue, which supports fast \textit{pop} operations, by exploiting characteristics of its underlying data structure. A skip list \cite{Pugh:1990:SLP:78973.78977} was chosen because it provides probabilistic balancing using multiple levels, and maintains an ordered list of keys.

A heap-based concurrent priority queue designed for CUDA's data parallel SIMT architecture is presented in \cite{DBLP:conf/hipc/HeAP12}.
The authors use wide heap nodes in order to support thousands of push and pop operations at the same time.
Sundell et al.~\cite{Sundell:2005:FLC:1073765.1073770} present a lock-free concurrent priority queue which uses a skip list, as the underlying data structure.
Our lock-free implementation also uses a skip list, but different algorithms are used. Furthermore, our comparison is not limited to a lock-based implementations, but to other available ones. 

% TODO Xeon CPU or i7?
The rest of this paper is organized as follows.
In the next section we give a brief, yet sufficient, description of priority queues and skip lists. 
Then, a detailed description of our implementation is presented in section \ref{sec:approach}.
Section \ref{sec:exp} describes experimental results collected from a Xeon CPU and Xeon Phi, by comparing the lock-free implementation with the Intel Threading Building Blocks (TBB) concurrent priority queue, and two different implementations using mutual exclusion.
Finally, section~\ref{sec:con} concludes this work.

%\mypar{Related work} Next, you have to give a brief overview of related work. For a paper like this, anywhere between 2 and 8 references. Briefly explain what they do. In the end contrast to what you do to make now precisely clear what your contribution is.
